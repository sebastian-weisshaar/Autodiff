{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"7f0d28aa6f5149c7b34f124634997088","deepnote_cell_type":"markdown","tags":[]},"source":["# *autodiff* Documentation\n","#### Group members: Robin Robinson, Anna Midgley, Nora Hallqvist, Sebastian Weisshaar"]},{"cell_type":"markdown","metadata":{"cell_id":"2c776cb8c5654691b1106192939124a9","deepnote_app_coordinates":{"h":5,"w":12,"x":0,"y":4},"deepnote_cell_type":"markdown","tags":[]},"source":["\n","# 1. Introduction\n","\n","There are four main approaches to computing the derivative which are namely manual, symbolic, numerical, or automatic differentiation. Manual differentiation is the calculation of the derivative expression by hand and its coding. It is time-consuming and prone to error especially as systems become more complex. Numerical differentiation is the finite difference approximation of the derivative using values of the original function evaluated at points. Its advantage is that it is easy to implement whilst its disadvantage is truncation and round-off errors. Symbolic differentiation uses packages such as Mathematica, to produce the exact derivative expression as its output. It addresses the weaknesses of manual and numerical differentiation; however, it frequently results in “expression swell”. Expression swell is the phenomenon of much larger representation of a derivative as opposed to representation of the original function. Symbolic differentiation does not consider the fact that many sub-expressions in the different derivative expressions are common. This leads to inefficiency in its calculation. Symbolic and manual differentiation require the model to be defined as closed-form expressions which limits the expressivity of the model as it cannot use branches or loops. The fourth technique, automatic differentiation (AD), obtains the exact result of the derivative by breaking down the expression into elementary arithmetic operations and elementary functions and applying the chain rule to the derivatives of these operations.\n","\n","\n","# 2. Background\n","\n","### **Automatic Differentiation**\n","\n","The key idea of Automatic Differentation is to decompose the calculations into elementary functions and  evaluate the functions derivative by combining each elementary function's derivative by using the chain rule.\n","\n","Important components of Automatic Differenatiomn include the chain Rule, computational graph, evaluation trace, the seed vector and dual numbers. Elementts which are described below:\n","\n","\n","### **Chain Rule**\n","\n","The **chain rule** is a method to differentiate composite functions. This is especially useful in automatic differentation when extended to the multivariate case.\n","\n","For example, suppose we have a multivariate function $f(u_{1}(t),u_{2}(t))$ and we want to evaluate the derivative $f$ with respect $t$: \n","\n","$$ \\frac{\\partial f(u_{1}(t),u_{2}(t))}{\\partial t} = \\frac{\\partial f}{\\partial u_{1}}\\frac{\\partial u_{1}}{\\partial t} + \\frac{\\partial f}{\\partial u_{2}}\\frac{\\partial u_{2}}{\\partial t}$$\n","\n","The above can also be represented in vector notation. Replacing $t$ with $x \\in R^{m}$, the chain rule can more elegantly be written in terms of the differential vector operator $\\nabla$ with respect to the vector $x$.\n","\n","$$\\nabla_{x}f = \\frac{\\partial f}{\\partial u_{1}}\\nabla_{x}u_{1}  + \\frac{\\partial f}{\\partial u_{2}}\\nabla_{x}u_{2}  \\text{ where } f = f(u_{1}(x_{1},...,x_{m}),u_{2}(x_{1},...,x_{m}))$$\n","\n","\n","Automatic differentiation commonly involves several dependent variables (i.e intermediate steps), hence we need to generalize the chain rule to support a function $f$ of $n$ other functions i.e \n","\n","$$f(u_{1}(x_{1},...,x_{m}),u_{2}(x_{1},..,x_{m}),..,u_{n}(x_{1},..,x_{m}))$$\n","\n","Now the gradient of $f$ is instead given by: \n","\n","$$\\nabla_{x}f = \\sum_{i=1}^{n} \\frac{\\partial f}{\\partial u_{i}(x)} \\nabla_{x}u_{i}(x) \\text{ where } x \\in R^{m}$$\n","\n","\n","\n","\n","### **Compuational Graph**\n","\n","Automatic differentiation can be represented as a graph structure. This is done by decomposing the function into its primitive operations (e.g binary arithmic operations and unary operations). The computation graph is then simply constructed by representing each elementary operation as a node, and connecting each node by an edge. \n","\n","By convention the nodes are represented by the following variables:  \n","- Input variables : $v_{i-m} = x_{i}$ , $i = 1,...,m$\n"," - Intermediate variables: $v_{i}$ , $i = 1,..,n$\n","\n","An example of a computational graph is shown below for the function $f(x)=sin(x_1x_2) + x_2$,\n","\n","![](computationalgraph_example.png)\n","\n","### **Evaluation Trace**\n","\n","The evaluation trace stores the intermediate results $v_{i}$ evaluated at a given point, and includes a tangent trace, which records the directional derivative of each intermediate variable $v_{i}.$ The final derivative of the original function is calculated by combining derivatives of the intermediate results by using the chain rule.\n","\n","Below is an example of an evaluation trace table using the previous example function and computational graph:  \n","  \n","| **Primal Trace**  | **$f(x)$**              |\n","|-------------------|-------------------------|\n","| $v_{-1} = x_1$    | $v_{-1} = x_1$          |\n","| $v_{0} = x_2$     | $v_{0} = x_2$           |\n","| $v_1 = v_{-1}v_0$ | $v_1 = x_1x_2$          |\n","| $v_2 = sin(v_1)$  | $v_2 = sin(x_1x_2)$     |\n","| $v_3 = v_2 +v_0$  | $v_3 = sin(x_1x_2)+x_2$ |\n","  \n","<br>\n","\n","| **Tangent Trace**                                                               | $\\frac{\\partial f}{\\partial x_1}$ --> Direction: $p = [1, 0]^T$ | $\\frac{\\partial f}{\\partial x_2}$ --> Direction: $p = [0, 1]^T$          |\n","|---------------------------------------------------------------------------------|-----------------------------------------------------------------|--------------------------------------------------------------------------|\n","| $D_pv_{-1} = p_1$                                                               | $D_pv_{-1} = 1$                                                 | $D_pv_{-1} = 0$                                                          |\n","| $D_pv_{0} = p_2$                                                                | $D_pv_{0} = 0$                                                  | $D_pv_{0} = 1$                                                           |\n","| $D_pv_{1} = v_{-1}D_pv_{0} + v_{0}D_pv_{-1} = x_1p_2 + x_2 p_1$                 | $D_pv_{1} =x_2 p_1 = x_2$                                       | $D_pv_{1} =x_1 p_0 = x_1$                                                |\n","| $D_pv_{2} = cos(v_1)D_pv_{1}= cos(x_1 x_2)(x_1p_2 + x_2 p_1)$            | $D_pv_{2} = cos(x_1x_2)(x_2 p_1) = cos(x_1 x_2)(x_2)$    | $D_pv_{2} = cos(x_1 x_2)(x_1 p_2)$                                       |\n","| $D_pv_{3} = D_pv_{2} + D_pv_{0} = cos(x_1 x_2)(x_1p_2 + x_2 p_1) + p_2$  | $D_pv_{3} = cos(x_1 x_2)(x_2)$                                  | $D_pv_{3} = cos(x_1 x_2)(x_1 p_2) + p_2 = cos(x_1 x_2)(x_1) + 1$  |\n","\n","\n","  \n","### **Seed vector**\n","The methods mentioned above describe how to calculate the derivative of a function using a computational graph. However, we also have to consider the direction of the derivative. We could be interested in the derivative in the direction of a specific input variable or in a different direction. To find the derivative in the direction that we are interested in we input a seed vector into the graph. This seed vector described the direction of the desired derivative and is used in the various steps of calculating the derivative. For example, if we are interested in $\\frac{\\partial f(x_1,x_2)}{\\partial x_1}$ we would input $[1,0]^T$ as our seed vector to indicate the direction of the derivative we are interested in. \n","  \n","    "]},{"cell_type":"markdown","metadata":{"cell_id":"40288dc511dd411290b0db26a63dcd0d","deepnote_cell_type":"markdown","tags":[]},"source":["### **Dual Numbers**\n","\n","A dual number is given by the expression:\n","\n","$$z = a + b \\epsilon \\text{ such that }  \\epsilon>0 \\text{ and }  \\epsilon^{2}=0$$\n","\n","\n","Similiar to complex numbers, dual numbers adhere to the following rules for addition and multiplication:\n","\n","$$z_{1} + z_{2} = (a_{1}  + a_{2})  + (b_{1} + b_{2}) \\epsilon$$\n","$$z_{1} z_{2} = (a_{1} *a_{2})  + (a_{1}*b_{2} + a_{2}*b_{1}) \\epsilon$$\n","\n","\n","Let the real part be equal to the functions $f_{1}(x) \\text{ and } f_{2}(x)$ (i.e $a_{1} = f_{1}(x) \\text{ and } a_{2} = f_{2}(x) $ ) and the dual part be equal to their respective derivatives (i.e $ b_{1} = f_{1}'(x) \\text{ and } b_{2} = f_{2}'(x)$). Then we get the following expressions: \n","\n","$$z_{1} + z_{2} = (f_{1}  + f_{2})  + (f_{1}'(x) + f_{2}'(x)) \\epsilon$$\n","$$z_{1} z_{2} = (f_{1}f_{2})  + (f_{1}f_{2}'(x) + f_{2}f_{1}'(x)) \\epsilon$$\n","\n","\n","By using dual numbers in forward automatic differentiation, both the primal and tangent trace can be carried as a pair. This can be seen by letting the functions represent the intermediate results in the primal trace (i.e $f_{i}(x) = v_{i}$) and the functions' derivatives be equal to the tangent trace (i.e $f_{i}'(x) = D_{p}v_{i})$.\n","\n","For dual numbers to be useful in automatic differentiation, a function applied to a dual number must satisfy the chain rule. In general, any analytic function can be extended to the dual numbers by looking at the function's taylor series: \n","\n","$$f(z) = f(a+b\\epsilon) = f(a) + bf'(a)\\epsilon$$\n","\n","note: all higher terms disappear since $\\epsilon^{0}=0$\n","\n","Applying the function $f$ on the dual number $z_{i} = v_{i} + D_{p}v_{i}\\epsilon$, we see that any analytic function applied to a dual number returns another dual number:\n","\n","$$f(z_{i}) = f(v_{i}+ D_{p}v_{i}\\epsilon) = f(v_{i}) + f'(v_{i})D_{p}v_{i}\\epsilon$$\n","\n","From the above expression we can see that the dual part is equal to the dual part of $z_{i} \\text{ times by }  f'(v_{i})$  **i.e the chain rule**\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"cell_id":"32798ae8e02c4ad3aee4ac46796e749e","deepnote_cell_type":"markdown","tags":[]},"source":["An example of how dual numbers can be used in the forward pass in automatic differentiation is shown below using the previous example. It shows how binary arithmatic operations on dual number maintain the correct value of the primal and tangent trace of the new node. This is shown for the addition of node $v_2$ to $v_0$ to become $v_3$.  \n","\n","$v_3 = v_2 + v_0 = (f_2 + f_0) + (f'_2 + f'_0)\\epsilon$ \n","\n","$v_3 = \\left(sin(x_1x_2) + x_1\\right) + \\left(\\cos(x_1x_2)(x_1p_2+x_2p_1) + p_1\\right)\\epsilon$\n","\n","It should be noted that we will not use dual numbers. However, the principles we have just mentioned will be maintained in the Node class.  \n"]},{"cell_type":"markdown","metadata":{"cell_id":"2de1475c58584ca9b79990c17dada813","deepnote_app_coordinates":{"h":5,"w":12,"x":0,"y":10},"deepnote_cell_type":"markdown","tags":[]},"source":["# How to Use *autodiff*\n","\n","### **Installation**\n","To install the *autodiff* package, use `pip install autodiff`\n","\n","### **Usage**\n","\n","The name of our package is *autodiff*. Its functionality is to provide the user with methods to undergo automatic differentiation of both univariate and multivariate functions. We envision the user should import the autodiff and functions modules. The imported unary functions should be used to define the function that is to be evaluated. This function can either be a scalar or an array, however a scalar function must be places in a list. The user should define an input and seed, and these parameters are used to instantiate the AutoDiff class. The input is the point at which the derivative/function is evaluated at. The seed is the vector direction at which the derivative is computed in, commonly denoted as $p$. The seed vector must be the same shape as the input vector. The user can access forward or backward mode by calling their respective methods in the AutoDiff class.\n","<br>\n","\n","**Basic Demo :** *An example of how we envision the user would interact with the package*\n","\n","\n","```Python\n","import autodiff as AD\n","from functions import sin,log\n","\n","\n","f = lambda x: [log(x[0]) + sin(x[0]+x[1])] #user specified/created function \n","input = [1,1] \n","seed = [1,0]\n","diff_f = AD.AutoDiff(f,input,seed)\n","forward_mode = diff_f.forward() #returns derivative value using forward mode\n","backward_mode = diff_f.backward() #returns derivative value using reverse mode\n","eval_func = diff_f.function_value() #returns function value evaluated at input \n","\n","print(forward_mode)\n","> 0.5838531634528576\n","print(eval_func)\n","> 0.9092974268256817\n","\n","```\n"]},{"cell_type":"markdown","metadata":{"cell_id":"8eb143894de640f284bab7b9547c0edb","deepnote_app_coordinates":{"h":5,"w":12,"x":0,"y":16},"deepnote_cell_type":"markdown","tags":[]},"source":["# Organizational Structure  \n","\n","### **Directory Structure**\n","\n","The Directory takes the following structure:\n","\n","|-- src/\n","\n","|&emsp;|-- Autodiff/\n","\n","|&emsp;|&emsp;|-- \\_\\_init__.py\n","\n","|&emsp;|&emsp;|-- autodiff.py\n","\n","|&emsp;|&emsp;\\\\-- functions.py\n","\n","|&emsp;|-- demo\n","\n","|&emsp;\\\\-- tests\n","\n","|-- Docs/\n","\n","|&emsp;\\\\-- README.md\n","\n","|-- LICENSE\n","\n","|-- pyproject.toml\n","\n","\\\\-- README.md\n"]},{"cell_type":"markdown","metadata":{"cell_id":"6a253ad63b5c46bb998d817fcc9c8b0c","deepnote_app_coordinates":{"h":5,"w":12,"x":0,"y":22},"deepnote_cell_type":"markdown","tags":[]},"source":["### **Modules**\n","- **\\_\\_init__.py**: Imports all of the necessary modules\n","\n","- **autodiff.py**: Contains the AutoDiff & Node class.\n","    1. **AutoDiff Class**\n","        <br>\n","        - The AutoDiff class is the main interface between the user and the package. \n","        - The class takes in a function, input vector, and seed vector. \n","        - It provides the user the functionality to compute the derivative using either forward or reverse mode, and the function evaluation.\n","    <br>\n","    <br>\n","    2. **Node Class**\n","        <br>\n","        - The Node class is the main data structure which stores the information of the a specific node in the computational graph including name, value, child, parents, and adjoint. \n","        - In addition the Node class overloads the binary arithmatic operations. \n","        \n","        **Example: we have overloaded the the binary arithmatic operations in the following manner**\n","\n","        ``` Python\n","        def __add__(self, other):\n","            if isinstance(other, Node):\n","                new_name = max(self.name, other.name) + 1\n","                value = self.value + other.value\n","                for_deriv = self.for_deriv + other.for_deriv\n","                back_deriv = {self.name: 1, other.name: 1}\n","                parents = [self, other]\n","                new_node = Node(new_name, value, for_deriv=for_deriv, back_deriv=back_deriv,\n","                                parents=parents)\n","                other.child.append(new_node)\n","\n","            elif isinstance(other, (float, int)):\n","                new_name = self.name + 1\n","                value = self.value + other\n","                for_deriv = self.for_deriv\n","                back_deriv = {self.name: 1}\n","                parents = [self]\n","                new_node = Node(new_name, value, for_deriv=for_deriv, back_deriv=back_deriv,\n","                                parents=parents)\n","            else:\n","                raise TypeError\n","            self.child.append(new_node)\n","            return new_node\n","\n","        def __radd__(self, other):\n","            return self.__add__(other)\n","        ```\n","    \n","- **functions.py**: Contains defined unary functions for a node, float or int\n","    <br>\n","    - The following functions are included: sin,cos,tan,arcsin,arcos, arctan, sinh,cosh,tanh, sqrt, exp (any base), log (any base), sigmoid\n","    - A valid input to the functions include an object of the Node class, float or int\n","    \n","    **Example: unary functions have been implemented in the following manner**\n","\n","    ``` Python\n","    def sin(var):\n","    \n","    if isinstance(var, Node):\n","        new_name = var.name + 1\n","        for_deriv = np.cos(var.value)*var.for_deriv\n","        back_deriv = {var.name: np.cos(var.value)}\n","        new_node = Node(new_name, np.sin(var.value), for_deriv=for_deriv, back_deriv=back_deriv, parents=[var])\n","        var.child.append(new_node)\n","        return new_node\n","    elif isinstance(var, (int, float)):\n","        return np.sin(var)\n","    else:\n","        raise TypeError   \n","    ```\n","\n","### **Demo and Test Suite**\n","Both the test and demo suites will live in the root directory under the *tests*. The test folder will contain Python files that test the AutoDiff class. The demo folder will contain example usages of the package. \n","TODO: Where do tests live? How are they run? How are they integrated?\n","\n","### **Package Distribution**\n","The package will be distributed using PyPI with PEP517/518. We will add a pyproject.toml file to our project. This enables us to build our package using a PEP517 builder and distribute our package using PyPI. Other developers can install it using pip install. \n"]},{"cell_type":"markdown","metadata":{"cell_id":"1f88f3ca16534432b41083aa7cb7683a","deepnote_app_coordinates":{"h":5,"w":12,"x":0,"y":28},"deepnote_cell_type":"markdown","tags":[]},"source":["# Implementation\n","\n","The table below lists all of the classes needed to implement forward mode, with their respective methods and attributes. The core data structure are Nodes which are used for both forward and reverse mode. \n","\n","| **Class**      | **AutoDiff**               | **Node**                                                                                      |\n","|----------------|----------------------------|------------------------------------------------------------------------------------------------------|\n","| **Attributes** &emsp;&emsp;| f, input, seed,       | name, value, child, parent, for_deriv, back_deriv, adjoint,                                                                                            |   |   |\n","| **Methods**    | function_value, forward, backward &emsp;&emsp;| \\_\\_add__, \\_\\_radd__, \\_\\_mul__, \\_\\_rmul__, \\_\\_truediv__, \\_\\_rtruediv__, \\_\\_pow__, \\_\\_neg__, \\_\\__new_name__ ,   \\_\\__str__| \n","\n","<br>\n","\n","\n","As mentioned earlier, for the Node class, we will overload the binary arithmatic operations. Unary functions such as 'sin' or 'log' will be defined in functions.py file for the Node data structures. These functions will work for both forward and reverse mode of AD, because both rely on the Node data structure. \n","\n","We will not use DualNumbers, this is due to the fact that dual numbers as the primary data structure can only be used in forward mode. If we decide to implement reverse mode, this will result in redundancy of code, as we would need to define a different data structure.  \n","\n","We would like our package to be able to compute the derivative of both scalar and vector functions that can depend on both scalar and vector parameters. To ensure this, we have two requirements for how the user defines the function. The first is that the input of the function must be the same size as the number of parameters (m). The second is that the function that is passed to the AutoDiff must be a list or an array of functions of size of the number of outputs (n).    \n","\n","**Example:** A vector function (m=2 and n=3)\n","\n","\n","$\\textbf{f}(\\textbf{x}) = \\begin{bmatrix}\n","x_{1} + x_{2}\\\\\n","\\sin(x_{1}) \\\\\n","\\cos(x_{1}x_{2})\n","\\end{bmatrix}$\n","\n","```Python\n","def f(x):\n","    return [x[0] + x[1], sin(x[0]), cos(x[0]*x[1])]\n","```\n","\n","\n","We will depend on the Numpy library, and no other libraries at this stage. We will use Numpy to define the unary functions, to ensure that the functions are evaluated efficienctly. An intentional decision was made to not depend on other libraries to ensure the package had lightweight requirements. "]},{"cell_type":"markdown","metadata":{},"source":["# Future Features\n","\n","We plan to implement a **Reverse Mode** functionality.\n","\n","In **Reverse Mode**, the chain rule is not explicitly applied. Instead the partial derivatives with respect to the node's parent node(s) is calculated in the forward pass and in the reverse pass the chain rule is reconstructed. The chain rule is \"built up\" in the reverse pass by traversing the computational graph backwards and consequently recovering the partial deritiaves of the i-th output of $f_i$ with respect to the $n$ variables $v_{j-m}$ with $j=1,2,..,n$. For each node $v_{i}$ the goal is to calculate the adjoint $\\bar{v}_{i}$  by iterating over all its children i.e \n","\n","$$\\bar{v}_{i} = \\frac{\\partial f}{\\partial v_{i}} = \\sum_{j \\text{ a child of i } } \\frac{\\partial f}{\\partial v_{j}}\\frac{\\partial v_{j}}{\\partial v_{i}}$$\n","\n","\n","Consequenlty, to implement **Reverse Mode** we need to keep track of a node's parents, children, its partial derivatives with respect to its parent node(s) and its adjoint. This will be accomplished by storing all the above as attributes in the Node Class.\n","\n","``` Python\n","class Node:\n","    def __init__(self, name: int, value=None, child=[], parents=[],\n","                 for_deriv=1, back_deriv={}):\n","        self.name = name\n","        self.value = value\n","        self.child = child\n","        self.parents = parents\n","        self.for_deriv = for_deriv\n","        self.back_deriv = back_deriv \n","        self.adjoint = 0\n","``` \n","\n","Further, the unary functions will be constructed to return a dictionary of partial derivatives with respect to the its parent node(s). \n","The unary functions will be implemented in a similiar manner to the following $cos$ function:\n","\n","```Python\n","def cos(var):\n","\n","    if isinstance(var, Node):\n","        new_name = var.name + 1\n","        for_deriv = -np.sin(var.value)*var.for_deriv\n","        back_deriv = {var.name: -np.sin(var.value)}\n","        new_node = Node(new_name, np.cos(var.value), for_deriv=for_deriv, back_deriv=back_deriv, parents=[var])\n","        var.child.append(new_node)\n","        return new_node \n","    elif isinstance(var, (int, float)):\n","        return np.cos(var)\n","    else:\n","        raise TypeError\n","```\n","\n","Lastly, the AutoDiff class will include a function called **backward** which implements the reverse pass of the **Reverse Mode**.\n","\n","We envision that the user interacts with the reverse mode functionality as follows: \n","\n","```Python\n","f = lambda x: ln(x[0]) + sin(x[0]+x[1]) #user specified/created function \n","input = [1,1] \n","seed = [1,0]\n","diff_f = AD.AutoDiff(f,input,seed)\n","backward_mode = diff_f.backward() #returns derivative value using Reverse Mode\n","\n","print(backward_mode)\n","> 0.5838531634528576\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"cell_id":"acb2671a323c421682d144bdb650d45a","deepnote_app_coordinates":{"h":5,"w":12,"x":0,"y":46},"deepnote_cell_type":"markdown","tags":[]},"source":["# Licensing\n"]},{"cell_type":"markdown","metadata":{"cell_id":"296edc87f6be4a54a2e59cb5d41f7a7e","deepnote_app_coordinates":{"h":5,"w":12,"x":0,"y":52},"deepnote_cell_type":"markdown","tags":[]},"source":["We chose the MIT license for our project. This choice was based on multiple aspects. For one we want to allow developers to develop proprietary software with our package. Therefore a copyleft license would not be suitable as it forces developers to make their source code public. With the MIT licencse, a copyright license, developers can build proprietary software. In this way our package has a practical advantage for many different types of coders.\n","\n","A second consideration is the dependency on libraries. The only library we depend upon is NumPy. This library is distributed under the liberal BSD license which is a copyright license. This means that we cannot disitrbute our own package under a copyleft license. Therefore we chose the copyright MIT license. \n","\n","For these reasons we selected the MIT license. A LICENSE file is included in the root to inform the user. "]}],"metadata":{"deepnote":{},"deepnote_app_layout":"article","deepnote_execution_queue":[],"deepnote_notebook_id":"641ddd0fb831472e931fd8fc1d1dfaf9","kernelspec":{"display_name":"Python 3.10.7 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.8"},"orig_nbformat":2,"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
